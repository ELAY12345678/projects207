{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKsRDH5ZUdfasdv"
   },
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\"> Submission requirements </span>\n",
    "\n",
    "Your work will not be graded if your notebook doesn't include output. In other words, <span style=\"color:red\"> make sure to rerun your notebook before submitting to Gradescope </span> (Note: if you are using Google Colab: go to Edit > Notebook Settings  and uncheck Omit code cell output when saving this notebook, otherwise the output is not printed).\n",
    "\n",
    "Additional points may be deducted if these requirements are not met:\n",
    "\n",
    "    \n",
    "* Comment your code;\n",
    "* Each graph should have a title, labels for each axis, and (if needed) a legend. Each graph should be understandable on its own;\n",
    "* Try and minimize the use of the global namespace (meaning, keep things inside functions).\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style=\"darkgrid\")  # default style\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab continues our study of linear regression. You'll train your first models with Tensorflow, using a real dataset to predict car prices from their features. Note that Tensorflow is a rapidly changing library. This means you'll often see warnings about deprecations. You can ignore the warnings in our labs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 1: Data ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHLcriKWLRe4"
   },
   "source": [
    "You'll use the [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile)  from 1985 Ward's Automotive Yearbook that is part of the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets).\n",
    "\n",
    "This dataset has been pre-downloaded and uploaded to bCourses alongside this notebook for your convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "load_auto_data_set_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (205, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>...</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "      <th>symboling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>2.0</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>...</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>2.0</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>168.8</td>\n",
       "      <td>...</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>2.0</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>171.2</td>\n",
       "      <td>...</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>176.6</td>\n",
       "      <td>...</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>4.0</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>176.6</td>\n",
       "      <td>...</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.40</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   normalized-losses         make fuel-type aspiration  num-of-doors  \\\n",
       "0                NaN  alfa-romero       gas        std           2.0   \n",
       "1                NaN  alfa-romero       gas        std           2.0   \n",
       "2                NaN  alfa-romero       gas        std           2.0   \n",
       "3              164.0         audi       gas        std           4.0   \n",
       "4              164.0         audi       gas        std           4.0   \n",
       "\n",
       "    body-style drive-wheels engine-location  wheel-base  length  ...  \\\n",
       "0  convertible          rwd           front        88.6   168.8  ...   \n",
       "1  convertible          rwd           front        88.6   168.8  ...   \n",
       "2    hatchback          rwd           front        94.5   171.2  ...   \n",
       "3        sedan          fwd           front        99.8   176.6  ...   \n",
       "4        sedan          4wd           front        99.4   176.6  ...   \n",
       "\n",
       "   fuel-system  bore  stroke compression-ratio  horsepower  peak-rpm city-mpg  \\\n",
       "0         mpfi  3.47    2.68               9.0       111.0    5000.0       21   \n",
       "1         mpfi  3.47    2.68               9.0       111.0    5000.0       21   \n",
       "2         mpfi  2.68    3.47               9.0       154.0    5000.0       19   \n",
       "3         mpfi  3.19    3.40              10.0       102.0    5500.0       24   \n",
       "4         mpfi  3.19    3.40               8.0       115.0    5500.0       18   \n",
       "\n",
       "   highway-mpg    price  symboling  \n",
       "0           27  13495.0          3  \n",
       "1           27  16500.0          3  \n",
       "2           26  16500.0          1  \n",
       "3           30  13950.0          2  \n",
       "4           22  17450.0          2  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_data_init = pd.read_csv(\"automobile_data.txt\")\n",
    "\n",
    "# Display top five rows\n",
    "print('Shape of data:', car_data_init.shape)\n",
    "car_data_init.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2: Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is essential for preparing the data in a format that is suitable for ML algorithms. It helps ensure data quality and improvements in model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 1:</span> Column selection (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple, you will:\n",
    "\n",
    "1. Retain only the following columns: ['horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']. Name the new dataframe *car_data*.\n",
    "2. Display the data type of each column;\n",
    "3. Convert the data type of each columns to numeric. Coerce missing values to NaN. Hint: use <span style=\"color:chocolate\">pd.to_numeric()</span> method;\n",
    "4. Display the data type of each column after the transformation performed at point 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horsepower     float64\n",
      "peak-rpm       float64\n",
      "city-mpg         int64\n",
      "highway-mpg      int64\n",
      "price          float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "cols = ['horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "car_data = car_data_init[cols].copy()\n",
    "\n",
    "car_data.head()\n",
    "\n",
    "car_data = car_data.apply(pd.to_numeric)\n",
    "print(car_data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 2:</span> Example (row) selection (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things simple again, you will:\n",
    "\n",
    "1. Print the shape of the car_data;\n",
    "\n",
    "2. Remove examples (rows) that have missing value(s). Note that in doing so, you will overwrite the car_data dataset. You should end up with 199 examples after this cleaning.\n",
    "\n",
    "3. Print the shape of the car_data again.\n",
    "\n",
    "It's important to acknowledge that there are multiple approaches to handling missing features, and simply discarding examples with any missing feature, though straightforward, may not be the most optimal solution. However, for the sake of simplicity, you will implement this strategy in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(205, 5)\n",
      "(199, 5)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "print(car_data.shape)\n",
    "car_data = car_data.dropna()\n",
    "print(car_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 3:</span> Data shuffling (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you'll be using Batch Gradient Descent (BGD) for training, it is important that **each batch is a random sample of the data** so that the gradient computed is representative. Note that the original data (above) appears sorted by *make* in alphabetic order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NumPy and Pandas methods:\n",
    "\n",
    "1. Create a list of indices corresponding to the rows in the car_data dataset. Call this list *indices*. Print this list;\n",
    "\n",
    "2. Shuffle *indices* using the <span style=\"color:chocolate\">np.random.permutation()</span> method. Call the resulting array *shuffled_indices*. Print this array;\n",
    "    \n",
    "3. Use the method <span style=\"color:chocolate\">dataframe.reindex()</span> to change the ordering of the car_data dataset based on the order in the *shuffled_indices* array. Note that in doing so, you will overwrite the original dataset. Print the top 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204]\n",
      "[ 19 175 109  95 182 189   5 145  13 166  64 127 170 151  83   7  34 135\n",
      "  38  77 165 150  48 164  63 125 184 190 100  47  17  58  86 113  23 194\n",
      " 141   4 143 199 159  69  27 137 152  66   8  78 101 172  74 202  89  99\n",
      " 155  25  31 116  41  59 136 188 186  20 158 142  57 168  54 115 144  92\n",
      "  93 126 149 187 111  15  28 104 121  49 200 110  65   2  62 179 132  46\n",
      "  11 192  76 197 183 173 128  96 114 163 196  53   0  97 112  98  67 147\n",
      "  42  72  52  51  88  14 156  24 191 140  21  16  81 107  55 103  79   3\n",
      " 119 169 203   6  71  87 124 160 176 161  94 177  12 122 105  36  60  68\n",
      "   1 123 167  43 108 138 204  18  39 139  56 162 134  35  29 117 157  32\n",
      " 185 133 181  33 148 174 153  30 102  85  82 118 154 201  75  80  26 171\n",
      "  84 193 180 195  40  61 146  91  73  90  37  22  10 106  70 198 120  50\n",
      " 178]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>70.0</td>\n",
       "      <td>5400.0</td>\n",
       "      <td>38</td>\n",
       "      <td>43</td>\n",
       "      <td>6295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>92.0</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>9988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>97.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>12440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>69.0</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>7799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>52.0</td>\n",
       "      <td>4800.0</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "      <td>7775.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     horsepower  peak-rpm  city-mpg  highway-mpg    price\n",
       "19         70.0    5400.0        38           43   6295.0\n",
       "175        92.0    4200.0        27           32   9988.0\n",
       "109        97.0    5000.0        19           24  12440.0\n",
       "95         69.0    5200.0        31           37   7799.0\n",
       "182        52.0    4800.0        37           46   7775.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "# YOUR CODE HERE\n",
    "\n",
    "indices = car_data.index.to_list()\n",
    "print(indices)\n",
    "\n",
    "shuffled_indices = np.random.permutation(indices)\n",
    "print(shuffled_indices)\n",
    "\n",
    "car_data = car_data.reindex(shuffled_indices)\n",
    "car_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 4:</span> Define outcome and features (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two dataframes as follows:\n",
    "\n",
    "1. The first dataframe contains our outcome of interest: ['price']. Note, this is what we are aiming to predict. Name this dataframe Y. Print shape of Y.\n",
    "2. The second dataframe contains our features of interest: ['horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg']. Name this dataframe X. Print shape of X.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 1)\n",
      "(199, 4)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "Y = car_data[['price']]\n",
    "print(Y.shape)\n",
    "\n",
    "x_cols = ['horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg']\n",
    "X = car_data[x_cols]\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 5:</span> Data splits (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the <span style=\"color:chocolate\">train_test_split()</span> method available in scikit-learn:\n",
    "1. Partition the (X, Y) data into training, validation, and test sets using a splitting rule of [60%, 20%, 20%], with a random state set to 1234. Name the resulting dataframes as follows: X_train, X_val, X_test, Y_train, Y_val, Y_test. Hint: To create these three partitions you will utilize the train_test_split() method twice (all the other arguments of the method are set to default values.). You should obtain [119, 40, 40] examples for training, validation, and test, respectively.\n",
    "2. Print the shape of each dataframe.\n",
    "\n",
    "Note: The validation set is crucial for evaluating different hyperparameter configurations and selecting those that yield optimal model performance. This approach avoids utilizing the test dataset during model training, as it is assumed to be \"unknown\" at that stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 4) (40, 4) (40, 4) (119, 1) (40, 1) (40, 1)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "X_temp, X_test, Y_temp, Y_test = train_test_split(X,Y, test_size=0.2, random_state=1234, shuffle=True)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_temp,Y_temp, test_size=0.25, random_state=1234, shuffle=True)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 6:</span> Data standardization (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this concept in mind, complete the following tasks:\n",
    "\n",
    "1. Output the quantile values (0.25, 0.5, 0.75, 0.95) for all features in the X_train dataset. Are these values uniformly scaled across features?\n",
    "\n",
    "2. Standardize all features in X_train, X_val, and X_test. Label the resulting dataframes as X_train_std, X_val_std, and X_test_std, respectively. Hint: standardize the validation and test data using the mean and standard deviation computed from the training data. Why?\n",
    "\n",
    "3. Similar to point 2. but now standardize the outcome variable. Label the resulting dataframes as Y_train_std, Y_val_std, and Y_test_std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      horsepower  peak-rpm  city-mpg  highway-mpg\n",
      "0.25        69.0    4800.0      21.0         25.0\n",
      "0.50        90.0    5100.0      25.0         30.0\n",
      "0.75       116.0    5400.0      31.0         37.0\n",
      "0.95       176.6    5810.0      37.0         42.1\n",
      "horsepower      107.6\n",
      "peak-rpm       1010.0\n",
      "city-mpg         16.0\n",
      "highway-mpg      17.1\n",
      "dtype: float64\n",
      "horsepower      100.092437\n",
      "peak-rpm       5084.873950\n",
      "city-mpg         25.739496\n",
      "highway-mpg      31.352941\n",
      "dtype: float64 horsepower      37.186107\n",
      "peak-rpm       451.400930\n",
      "city-mpg         6.339767\n",
      "highway-mpg      6.758236\n",
      "dtype: float64      horsepower  peak-rpm  city-mpg  highway-mpg\n",
      "97    -0.836130  0.255042  0.829763     0.835582\n",
      "154   -1.024373 -0.631089  0.198825     0.095744\n",
      "63    -0.970589 -0.963387  1.618436     1.575420\n",
      "161   -0.809239 -0.631089  0.356560     0.391679\n",
      "140   -0.728563 -1.517219  0.041091    -0.052224\n",
      "..          ...       ...       ...          ...\n",
      "80     0.427782  0.919639 -0.432113    -0.200191\n",
      "151   -1.024373 -0.631089  0.829763     0.983549\n",
      "48     2.041288 -0.741855 -1.693989    -1.827835\n",
      "16     2.202639  0.698107 -1.536255    -1.383932\n",
      "7      0.266432  0.919639 -1.063051    -0.940030\n",
      "\n",
      "[119 rows x 4 columns]      horsepower  peak-rpm  city-mpg  highway-mpg\n",
      "40    -0.378970  1.584237  0.198825     0.243711\n",
      "192   -0.863022 -1.295686  1.145232     0.983549\n",
      "118   -0.863022  0.919639  1.776170     1.427452\n",
      "122   -0.863022  0.919639  0.829763     0.983549\n",
      "113   -0.136945 -0.188023 -1.063051    -1.087997\n",
      "136    1.611020  0.919639 -1.063051    -0.792062\n",
      "11     0.024406  1.584237 -0.432113    -0.348159\n",
      "56     0.024406  2.027302 -1.378520    -1.235965\n",
      "116   -0.136945 -2.071050  0.356560     0.243711\n",
      "125    1.153860  0.919639 -1.063051    -0.644094\n",
      "188   -0.002486  0.919639  0.041091     0.095744\n",
      "134    0.266432  0.365808 -0.747582    -0.496127\n",
      "119    0.051298  0.919639 -0.274379    -0.200191\n",
      "175   -0.217620 -1.960284  0.198825     0.095744\n",
      "179    1.637912  0.255042 -1.063051    -1.087997\n",
      "153   -1.024373 -0.631089  0.829763     0.835582\n",
      "66    -0.755455 -1.960284  0.829763     1.131517\n",
      "196    0.373999  0.698107 -0.274379    -0.496127\n",
      "27     0.051298  0.919639 -0.274379    -0.200191\n",
      "111   -0.136945 -0.188023 -1.063051    -1.087997\n",
      "35    -0.647888  2.027302  0.672029     0.391679\n",
      "126    2.874933  1.805770 -1.378520    -0.940030\n",
      "144   -0.486538 -0.631089 -0.274379    -0.940030\n",
      "8      1.073185  0.919639 -1.378520    -1.679868\n",
      "104    1.611020  0.255042 -1.063051    -0.940030\n",
      "127    2.874933  1.805770 -1.378520    -0.940030\n",
      "147   -0.163836  0.255042 -0.116644    -0.052224\n",
      "178    1.637912  0.255042 -0.905317    -1.087997\n",
      "79     0.051298  0.919639 -0.274379    -0.200191\n",
      "112   -0.136945 -2.071050  0.356560     0.243711\n",
      "74     2.256422 -1.295686 -1.851724    -2.271738\n",
      "64    -0.432754 -0.631089  0.041091     0.095744\n",
      "36    -0.647888  2.027302  0.672029     0.391679\n",
      "72     1.476561 -0.741855 -1.536255    -1.975803\n",
      "85    -0.325187 -0.188023 -0.116644     0.095744\n",
      "105    2.686691  0.255042 -1.378520    -1.235965\n",
      "99    -0.083161  0.255042  0.198825     0.391679\n",
      "115   -0.083161 -0.188023 -1.063051    -1.087997\n",
      "176   -0.217620 -1.960284  0.198825     0.095744\n",
      "84     1.207644 -0.188023 -1.063051    -1.087997      horsepower  peak-rpm  city-mpg  highway-mpg\n",
      "120   -0.863022  0.919639  0.829763     0.983549\n",
      "117    1.126968  1.141172 -1.220786    -1.087997\n",
      "58     0.938726  2.027302 -1.536255    -1.235965\n",
      "101    1.395886  0.255042 -1.378520    -1.383932\n",
      "20    -0.809239  0.698107  1.933905     1.723387\n",
      "59    -0.432754 -0.631089  0.041091     0.095744\n",
      "189   -0.271403  0.919639 -0.274379    -0.348159\n",
      "145    0.293324 -0.631089 -0.274379    -0.348159\n",
      "162   -0.809239 -0.631089  0.356560     0.391679\n",
      "42    -0.002486  0.919639 -0.116644    -0.052224\n",
      "139   -0.728563 -1.517219  0.041091    -0.052224\n",
      "155   -1.024373 -0.631089  0.198825     0.095744\n",
      "0      0.293324 -0.188023 -0.747582    -0.644094\n",
      "71     1.476561 -0.741855 -1.536255    -1.975803\n",
      "171    0.427782 -0.631089 -0.274379    -0.200191\n",
      "37    -0.378970  1.584237  0.198825     0.243711\n",
      "3      0.051298  0.919639 -0.274379    -0.200191\n",
      "47     2.041288 -0.741855 -1.693989    -1.827835\n",
      "149    0.293324 -0.631089 -0.432113    -1.235965\n",
      "142   -0.486538 -1.517219  0.356560     0.243711\n",
      "124    1.207644 -0.188023 -1.063051    -1.087997\n",
      "53    -0.863022 -0.188023  0.829763     0.983549\n",
      "102    1.395886  0.255042 -1.378520    -1.383932\n",
      "202    0.911834  0.919639 -1.220786    -1.235965\n",
      "76    -0.863022  0.919639  1.776170     1.427452\n",
      "51    -0.863022 -0.188023  0.829763     0.983549\n",
      "166    0.320215  3.356497  0.041091    -0.348159\n",
      "177   -0.217620 -1.960284  0.198825     0.095744\n",
      "146   -0.486538 -0.631089  0.356560     0.095744\n",
      "159   -1.185723 -1.295686  1.933905     2.315258\n",
      "5      0.266432  0.919639 -1.063051    -0.940030\n",
      "75     2.014396 -0.188023 -1.063051    -1.087997\n",
      "138   -0.836130 -0.409556  0.829763     0.687614\n",
      "1      0.293324 -0.188023 -0.747582    -0.644094\n",
      "55     0.024406  2.027302 -1.378520    -1.235965\n",
      "32    -1.078156  0.919639  1.933905     1.575420\n",
      "197    0.373999  0.698107 -0.274379    -0.496127\n",
      "180    1.503453  0.255042 -0.905317    -1.087997\n",
      "30    -1.131940 -0.631089  3.668984     3.351031\n",
      "41     0.024406  1.584237 -0.274379    -0.496127 price    12889.008403\n",
      "dtype: float64 price    8116.861682\n",
      "dtype: float64         price\n",
      "97  -0.602451\n",
      "154 -0.614894\n",
      "63  -0.257983\n",
      "161 -0.558222\n",
      "140 -0.651238\n",
      "..        ...\n",
      "80  -0.360978\n",
      "151 -0.807086\n",
      "48   2.791842\n",
      "16   3.502091\n",
      "7    0.743020\n",
      "\n",
      "[119 rows x 1 columns]         price\n",
      "40  -0.319583\n",
      "192  0.117778\n",
      "118 -0.901458\n",
      "122 -0.650499\n",
      "113  0.468899\n",
      "136  0.648156\n",
      "11   0.497235\n",
      "56  -0.128622\n",
      "116  0.623516\n",
      "125  1.124695\n",
      "188 -0.356543\n",
      "134  0.265003\n",
      "119 -0.607625\n",
      "175 -0.357405\n",
      "179  0.383029\n",
      "153 -0.735630\n",
      "66   0.672057\n",
      "196  0.381427\n",
      "27  -0.533582\n",
      "111  0.331531\n",
      "35  -0.689184\n",
      "126  2.419530\n",
      "144 -0.450421\n",
      "8    1.353478\n",
      "104  0.530992\n",
      "127  2.604331\n",
      "147 -0.331533\n",
      "178  0.452021\n",
      "79  -0.640643\n",
      "112  0.494155\n",
      "74   4.005365\n",
      "64  -0.202542\n",
      "36  -0.689184\n",
      "72   2.730981\n",
      "85  -0.726883\n",
      "105  0.838993\n",
      "99  -0.485410\n",
      "115  0.460891\n",
      "176 -0.245293\n",
      "84   0.197119         price\n",
      "120 -0.820515\n",
      "117  0.648156\n",
      "58   0.339539\n",
      "101  0.075151\n",
      "20  -0.777888\n",
      "59  -0.498223\n",
      "189 -0.159422\n",
      "145 -0.200818\n",
      "162 -0.447341\n",
      "42  -0.313423\n",
      "139 -0.718998\n",
      "155 -0.506478\n",
      "0    0.074658\n",
      "71   2.623550\n",
      "171 -0.165089\n",
      "37  -0.615263\n",
      "3    0.130715\n",
      "47   2.385280\n",
      "149 -0.147225\n",
      "142 -0.630047\n",
      "124 -0.015401\n",
      "53  -0.763104\n",
      "102  0.186031\n",
      "202  1.059029\n",
      "76  -0.924003\n",
      "51  -0.837024\n",
      "166 -0.412845\n",
      "177 -0.202173\n",
      "146 -0.668486\n",
      "159 -0.628446\n",
      "5    0.290875\n",
      "75   0.445245\n",
      "138 -0.957391\n",
      "1    0.444875\n",
      "55  -0.239502\n",
      "32  -0.922771\n",
      "197  0.446723\n",
      "180  0.345083\n",
      "30  -0.789715\n",
      "41   0.006898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Values differ, due to features are not uniformly scaled'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# quantiles\n",
    "quantiles = X_train.quantile([0.25, 0.50, 0.75, 0.95])\n",
    "print(quantiles)\n",
    "\n",
    "uniform_scaling = quantiles.max() - quantiles.min()\n",
    "print(uniform_scaling)\n",
    "\n",
    "#mean and std\n",
    "mu_X  = X_train.mean()\n",
    "sig_X = X_train.std(ddof=0) \n",
    "\n",
    "X_train_std = (X_train - mu_X) / sig_X\n",
    "X_val_std   = (X_val   - mu_X) / sig_X\n",
    "X_test_std  = (X_test  - mu_X) / sig_X\n",
    "\n",
    "#standardizing target value\n",
    "mu_y  = Y_train.mean()\n",
    "sig_y = Y_train.std(ddof=0)\n",
    "\n",
    "Y_train_std = (Y_train - mu_y) / sig_y\n",
    "Y_val_std   = (Y_val   - mu_y) / sig_y\n",
    "Y_test_std  = (Y_test  - mu_y) / sig_y\n",
    "\n",
    "#results\n",
    "\n",
    "print(mu_X, sig_X, X_train_std, X_val_std, X_test_std, mu_y, sig_y, Y_train_std, Y_val_std, Y_test_std)\n",
    "\n",
    "'''Values differ, due to features are not uniformly scaled'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3: Exploratory data analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA plays a very important role in ML. The goal here is to develop a good understanding of our training dataset, identify any data quality issues, understand patterns and relationships, which in turn, aids in subsequent modeling and interpretations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 7:</span> Scatterplot matrix (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will use some simple yet useful techniques to visualize the distribution of the data. \n",
    "\n",
    "Let's start with:\n",
    "\n",
    "1. A scatterplot matrix to visualize the pair-wise correlations between different features and outcome in the (X_train_std, Y_train_std) data. You will use the <span style=\"color:chocolate\">sns.pairplot()</span> method from the seaborn library imported at the top of the notebook;\n",
    "2. Is any of the variables in the data normally distributed? Is it necessary for the explanatory or target variable to be normally distributed in order to train a ML model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 8:</span> Correlation matrix (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will:\n",
    "\n",
    "1. Plot a correlation matrix in the form of a heatmap to visualize the linear relationships between different features and outcome in the (X_train_std, Y_train_std) data. Hint: this example here is very useful: https://seaborn.pydata.org/examples/many_pairwise_correlations.html\n",
    "    \n",
    "2. Answer the following questions: \n",
    " - Which two features are likely to be most redundant?\n",
    " - Which feature is likely to be least useful for predicting price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 9:</span> Baseline model (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by evaluating a baseline model. Precisely, you'll use the average price of cars in the training set as our baseline model -- that is, the baseline always predicts the average price regardless of the input.\n",
    "\n",
    "1. Implement this baseline using the Y_train_std data and print the average price. Note: You can revert the price variable to the original scale for interpretation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBXeXWygp4T"
   },
   "source": [
    "### <span style=\"color:chocolate\">Exercise 10:</span> Improvement over Baseline with TensorFlow (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDsxLnljlp0C"
   },
   "source": [
    "Let's train a linear regression model much like we did in the previous assignment, but this time using TensorFlow. \n",
    "\n",
    "1. Fill in the <span style=\"color:green\">NotImplemented</span> parts of the build_model() function below by following the instructions provided as comments. Hint: refer to the course webpage in <span style=\"color:chocolate\">bCourses/Modules/Module Demos/03 Features.ipynb</span> for an example.\n",
    "2. Build and compile a model using the build_model() function and the (X_train_std, Y_train_std) data. Set learning_rate = 0.0001. Call the resulting object *model_tf*.\n",
    "3. Train *model_tf* using the (X_train_std, Y_train_std) data. Set num_epochs = 5. Pass the (X_val_std, Y_val_std) data for validation. Hint: see the documentation behind the [tf.keras.Model.fit()](https://www.tensorflow.org/api_docs/python/tf/keras/Model) method.\n",
    "3. Generate a plot with the loss values on the y-axis and the epoch number on the x-axis for visualization. Make sure to include axes name and title. Hint: check what the [tf.keras.Model.fit()](https://www.tensorflow.org/api_docs/python/tf/keras/Model) method returns.\n",
    "\n",
    "More notes on point 1: the idea is to build a *computational graph* for linear regression, and then send data through it. There are many ways to build graphs, but [TenforFlow Keras API](https://www.tensorflow.org/api_docs/python/tf/keras) is recommended. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pfdRzjk-RgpG"
   },
   "outputs": [],
   "source": [
    "def build_model(num_features, learning_rate):\n",
    "  \"\"\"Build a TF linear regression model using Keras.\n",
    "\n",
    "  Args:\n",
    "    num_features: The number of input features.\n",
    "    learning_rate: The desired learning rate for SGD.\n",
    "\n",
    "  Returns:\n",
    "    model: A tf.keras model (graph).\n",
    "  \"\"\"\n",
    "  # This is not strictly necessary, but each time you build a model, TF adds\n",
    "  # new nodes (rather than overwriting), so the colab session can end up\n",
    "  # storing lots of copies of the graph when you only care about the most\n",
    "  # recent. Also, as there is some randomness built into training with SGD,\n",
    "  # setting a random seed ensures that results are the same on each identical\n",
    "  # training run.\n",
    "  tf.keras.backend.clear_session()\n",
    "  tf.random.set_seed(0)\n",
    "\n",
    "  # Build a model using keras.Sequential. While this is intended for neural\n",
    "  # networks (which may have multiple layers), we want just a single layer for\n",
    "  # linear regression.\n",
    "  model = tf.keras.Sequential()\n",
    "  model.add(tf.keras.layers.Dense(\n",
    "      units=NotImplemented,        # output dim\n",
    "      input_shape=NotImplemented,  # input dim\n",
    "      use_bias=True,               # use a bias (intercept) param\n",
    "      kernel_initializer=NotImplemented,  # initialize params to 1\n",
    "      bias_initializer=NotImplemented,    # initialize bias to 1\n",
    "  ))\n",
    "\n",
    "  # We need to choose an optimizer. We'll use GD, which is actually mini-batch GD\n",
    "  optimizer = NotImplemented\n",
    "\n",
    "  # Finally, compile the model. This finalizes the graph for training.\n",
    "  # We specify the MSE loss and the optimizer above\n",
    "  NotImplemented\n",
    "    \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "# 2. Build and compile model\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# 3. Fit the model\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 5: Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is a crucial step in optimizing ML models. It involves systematically adjusting hyperparameters such as learning rate, number of epochs, and optimizer to find the model configuration that leads to the best generalization performance.\n",
    "\n",
    "This tuning process is typically conducted by monitoring the model's performance on the validation vs. training set. It's important to note that using the test set for hyperparameter tuning can compromise the integrity of the evaluation process by violating the assumption of \"blindness\" of the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 11:</span> Hyperparameter tuning (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fine-tune the **learning rate** and **number of epochs** hyperparameters of *model_tf* to determine the setup that yields the most optimal generalization performance. Feel free to explore various values for these hyperparameters. Hint: you can manually test different hyperparameter values or you can use the [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner). If you decide to work with the Keras Tuner, define a new model building function named <span style=\"color:chocolate\">build_model_tuner()</span>.\n",
    "\n",
    "After identifying your preferred model configuration, print the following information:\n",
    "\n",
    "2. The learned parameters of the tuned model (this should include the bias term). Hint: use  <span style=\"color:chocolate\">[model_name].layers[0].get_weights()</span>.\n",
    "3. The loss at the final epoch on both the training and validation datasets;\n",
    "4. The difference between the last-epoch loss observed on the training and validation datasets.\n",
    "\n",
    "\n",
    "Please note that we will consider 'optimal model configuration' any last-epoch training loss that is below 0.31 and any last epoch validation loss that is below 0.48. Hint: do not specify the batch_size argument in the fit() function (it defaults to 32)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 6: Evaluation and Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that you've determined the optimal set of hyperparameters, it's time to evaluate your optimized (tuned) model on the test data to gauge its performance in real-world scenarios, commonly known as inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:chocolate\">Exercise 12:</span> Computing MSE (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Calculate the MSE on both (X_train_std, Y_train_std) and (X_test_std, Y_test_std) datasets. Hint: You can utilize the <span style=\"color:chocolate\">model.evaluate()</span> method provided by tf.keras.\n",
    "\n",
    "2. Does the model demonstrate strong generalization capabilities? Provide an explanation based on your observations. Hint: compare train vs. test MSE.\n",
    "\n",
    "4. Generate a plot to visualize the accuracy of the predictions. Plot the actual (observed) Y_test values on the x-axis and the predicted Y_test values on the y-axis. Additionally, include a 45-degree line in the plot for reference. Ensure that the plot contains appropriate axis labels and a title. Provide commentary on the model's fit based on this visualization. Hint: You can utilize the <span style=\"color:chocolate\">model.predict()</span> method available in tf.keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### <span style=\"color:chocolate\"></span> Additional practice (not graded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Exercise 12, you reported an aggregated MSE. Let's revisit the exercise by:\n",
    "\n",
    "1. Performing a subgroup evaluation of the model. Specifically, calculate the test data MSE for the following makes: ['alfa-romero', 'audi', 'chevrolet', 'dodge', 'honda'].\n",
    "2. Addressing the question: Is the model \"fair\" across each make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "copyright"
   ],
   "name": "03 Linear Regression with Tensorflow.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
