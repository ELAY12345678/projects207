{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "imcNmFXhPdCh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 15:55:47.690550: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-06 15:55:47.751700: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-06 15:55:48.279923: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-06 15:55:48.280314: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-06 15:55:48.400243: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-06 15:55:48.601811: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-06 15:55:48.604502: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-06-06 15:55:50.773510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import our standard libraries.\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns  # for nicer plots\n",
    "sns.set(style='darkgrid')  # default style\n",
    "import tensorflow as tf\n",
    "np.set_printoptions(precision=3, suppress=True)  # improve float readability\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4mROCY5wAX4"
   },
   "source": [
    "## Iris Classification\n",
    "\n",
    "We will train a classifier to predict 3 iris varieties from 4 features of each flower. Note: we are not doing image classification here!\n",
    "\n",
    "![An image](https://drive.google.com/uc?id=12gf4Q0K45gvw-tUDt_sWsbAl-f0klhib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "37XEUjK4ulzp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (150, 4)\n",
      "Y shape: (150,)\n",
      "feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "class names: ['setosa' 'versicolor' 'virginica']\n",
      "First example: [5.1 3.5 1.4 0.2] 0\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "Y = iris.target\n",
    "feature_names = iris.feature_names\n",
    "class_names = iris.target_names\n",
    "\n",
    "print('X shape:', X.shape)\n",
    "print('Y shape:', Y.shape)\n",
    "print('feature names:', feature_names)\n",
    "print('class names:', class_names)\n",
    "print('First example:', X[0], Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3GC13Sf219q"
   },
   "source": [
    "## Data Processing\n",
    "\n",
    "* Shuffle\n",
    "* Split into train/test\n",
    "* Apply mean and variance normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-sa_lrwU1oiT"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "shuffled_indices = np.random.permutation(range(len(Y)))\n",
    "X = X[shuffled_indices]\n",
    "Y = Y[shuffled_indices]\n",
    "\n",
    "X_train = X[0:100]\n",
    "Y_train = Y[0:100]\n",
    "X_test = X[100:150]\n",
    "Y_test = Y[100:150]\n",
    "\n",
    "X_train_means = np.mean(X_train, axis=0)\n",
    "X_train_stds = np.std(X_train, axis=0)\n",
    "X_train = (X_train - X_train_means) / X_train_stds\n",
    "X_test = (X_test - X_train_means)/ X_train_stds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4jIgCYbiVAz3"
   },
   "source": [
    "## Sparse vs Dense Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8bcduWsAbCRl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Convert Y from sparse to dense if needed\n",
    "# one-hot [0, 0, 1] -> 2\n",
    "# one-hot [0, 1, 0] -> 1\n",
    "# one-hot [1, 0, 0] -> 0\n",
    "Y_train_dense = tf.keras.utils.to_categorical(Y_train)\n",
    "print(Y_train_dense.shape)\n",
    "print(Y_train_dense[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FS7LIrIlVd2E"
   },
   "source": [
    "## Softmax Regression Functional Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tdGfEoDovBm"
   },
   "source": [
    "We will use *softmax regression*, which extends *logistic regression* to the multiclass setting. Our model will make predictions for input examples $X$ by:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{Y} = h_W(X) = \\phi(XW^T) =\n",
    "\\phi\\begin{pmatrix}\n",
    "x_{0,0} & x_{0,1} & x_{0,2} & x_{0,3} \\\\\n",
    "x_{1,0} & x_{1,1} & x_{1,2} & x_{1,3} \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "x_{m-1,0} & x_{m-1,1} & x_{m-1,2} & x_{m-1,3} \\\\\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "w_{0,0} & w_{1,0} & w_{2,0} \\\\\n",
    "w_{0,1} & w_{1,1} & w_{2,1} \\\\\n",
    "w_{0,2} & w_{1,2} & w_{2,2} \\\\\n",
    "w_{0,3} & w_{1,3} & w_{2,3} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{align}\n",
    "\n",
    "A few notes about this computation:\n",
    "\n",
    "* Our X has shape (100 x 4): 100 examples and 4 features\n",
    "* Our W has shape (3 x 4): 3 classes and 4 features. The indices above are reversed because we've taken the transpose of W: the first column of $W^T$ contains the weights for the first class.\n",
    "* The result will have shape (100 x 3): 3 probabilities corresponding to the 3 classes for each of the 100 examples.\n",
    "* $\\phi$ is the softmax function: $\\frac{e^{z_i}}{\\sum_j e^{z_j}}$. It is applied to the rows of $XW^T$.\n",
    "\n",
    "More detailed background [here](http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nAoIx-nkXhD-"
   },
   "source": [
    "## Softmax Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Hpah13BcCVXo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09  0.245 0.665]\n",
      " [0.016 0.117 0.867]]\n"
     ]
    }
   ],
   "source": [
    "# Remember the sigmoid function.\n",
    "def sigmoid(z):\n",
    "  return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Our softmax function will normalize over the rows of the input matrix.\n",
    "def softmax(z):\n",
    "  \"\"\"z has shape (m, n): examples, classes\"\"\"\n",
    "  (m, n) = z.shape\n",
    "\n",
    "  # First exponentiate each value\n",
    "  exps = np.exp(z)\n",
    "\n",
    "  # Get the sum of each row and normalize\n",
    "  row_sums = np.sum(exps, axis=1)\n",
    "  for i in range(m):\n",
    "    exps[i,:] /= row_sums[i]\n",
    "  \n",
    "  # Fancy/tricky way to do row-wise sums in numpy:\n",
    "  # return np.divide(exps.T, np.sum(exps, axis=1)).T\n",
    "\n",
    "  return exps\n",
    "\n",
    "# Try an example.\n",
    "v = np.array([[1,2,3],\n",
    "              [0,2,4]])\n",
    "print(softmax(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KLh6VWUfGm7_"
   },
   "source": [
    "## Making Predictions\n",
    "\n",
    "Now, given some initial parameter values (below), compute the model's initial predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "pGg1Ll4I4jR6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:\n",
      " [[0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]]\n",
      "label predictions:\n",
      " [0 0 0 0 0 0]\n",
      "true labels:\n",
      " [2 1 0 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "# Initial parameter values.\n",
    "# W = np.random.uniform(size=(3,4))\n",
    "W = np.ones((3,4))\n",
    "\n",
    "# Compute predictions.\n",
    "preds = softmax(np.dot(X_train, W.T))\n",
    "print('predictions:\\n', preds[:6])\n",
    "print('label predictions:\\n', np.argmax(preds, axis=1)[:6])\n",
    "print('true labels:\\n', Y_train[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIbpXB4ZHPvO"
   },
   "source": [
    "## Cross-Entropy Loss\n",
    "\n",
    "We'll use the general form of *cross-entropy* loss:\n",
    "\n",
    "\\begin{align}\n",
    "CrossEntropyLoss = \\frac{1}{m} \\sum_i \\sum_j -y_j\\log(\\hat{y_j})\n",
    "\\end{align}\n",
    "\n",
    "In this formula:\n",
    "\n",
    "* $j$ indexes the classes (in our case [0,1,2]) and each $y$ has a dense representation like [0,0,1] which indicates class 2.\n",
    "* *i* indexes over training examples, so we're computing an average loss (as usual)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lWxpr2OogN70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0986122886681093\n"
     ]
    }
   ],
   "source": [
    "def ce_loss(preds, Y):\n",
    "  \"\"\"\n",
    "    preds are (m,n) m = number of examples, n = number of classes\n",
    "    Y is (m,) -- array of sparse labels \n",
    "    preds[0] = [.1, .1, .8] Y[0] = 2 Y_dense[0] = [0, 0, 1]\n",
    "  \"\"\"\n",
    "  # Get the number of examples\n",
    "  m = Y.shape[0]\n",
    "\n",
    "  # Compute the first sum, the cross-entropy for each example, using\n",
    "  # the rows of the predictions and corresponding labels.\n",
    "  # Note that we need the dense (one-hot) labels.\n",
    "  Y_dense = tf.keras.utils.to_categorical(Y)\n",
    "  # [.1, .1, .8] [0, 0, 1] -> [0, 0, -1*log(.8)] -> -1*log(.8)\n",
    "  cross_entropy_values = - np.sum(Y_dense * np.log(preds), axis=1)\n",
    "\n",
    "  # Here's a more efficient but tricky way to do this:\n",
    "  # cross_entropy_values = -np.log(preds[range(m), Y])\n",
    "\n",
    "  # Sum the per-example cross-entropy values.\n",
    "  loss = np.sum(cross_entropy_values) / m\n",
    "\n",
    "  return loss\n",
    "\n",
    "#print(ce_loss(np.array([.1, .1, .8]), np.array([2])))\n",
    "print(ce_loss(preds, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaRg8b1F93w9"
   },
   "source": [
    "## Computing the Gradient\n",
    "\n",
    "Again, it will turn out that the gradient computation is the same as it was for MSE with linear regression. A happy coincidence.\n",
    "\n",
    "\\begin{align}\n",
    "\\nabla J(W) &= \\frac{1}{m}(h_W(X) - Y)^TX\n",
    "\\end{align}\n",
    "\n",
    "Remember that our parameters $W$ are represented by a matrix of shape (3 x 4): 3 classes and 4 features. The gradient will include a partial derivative for every parameter, and is an average over gradients computed on each training example.\n",
    "\n",
    "Let's review the matrix shapes:\n",
    "\n",
    "* $h_W(X)$ is (100 x 3): 3 probabilities for each example.\n",
    "* $Y$ is (100 x 3): this is the dense (one-hot) version of the labels, matching the shape of the predictions.\n",
    "* $X$ is (100 x 4): 4 features for each example.\n",
    "* The resulting product is (3 x 100)(100 x 4), giving a (3 x 4) output, which matches the shape of our parameters $W$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0-j0soKK2qfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradient:\n",
      " [[ 0.337 -0.28   0.431  0.411]\n",
      " [-0.042  0.191 -0.089 -0.046]\n",
      " [-0.295  0.09  -0.342 -0.365]]\n"
     ]
    }
   ],
   "source": [
    "# y' = [.1, .2, .7]  y = [0, 0, 1]  diff = y' - y = [.1, .2, -.3]\n",
    "# d1 = [.1, .2, -.3]  x1 = [1, 2, 3, 4]\n",
    "# (3 x 100) (100 x 4) -> (3 x 4)\n",
    "# [ [ .1*1,  .1*2,  .1*3,  .1*4 ]\n",
    "#   [ .2*1,  .2*2,  .2*3,  .2*4 ]\n",
    "#   [-.3*1, -.3*2, -.3*3, -.3*4 ]\n",
    "# ]\n",
    "#\n",
    "# We need the dense version of Y here\n",
    "m = Y_train.shape[0]\n",
    "Y_train_dense = tf.keras.utils.to_categorical(Y_train)\n",
    "diff = preds - Y_train_dense\n",
    "gradient = np.dot(diff.T, X_train) / m\n",
    "print('gradient:\\n', gradient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ExL4G-pMAXvV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.333]\n",
      " [ 0.333]\n",
      " [-0.667]]\n",
      "[[-0.017 -0.543  0.76   1.567]]\n",
      "gradient:\n",
      " [[-0.006 -0.181  0.253  0.522]\n",
      " [-0.006 -0.181  0.253  0.522]\n",
      " [ 0.011  0.362 -0.507 -1.045]]\n"
     ]
    }
   ],
   "source": [
    "# Simplify and just compute the gradient for the first training example.\n",
    "print(diff[0:1].T)\n",
    "print(X_train[0:1])\n",
    "print('gradient:\\n', np.dot(diff[0:1].T, X_train[0:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZDyrbc42rcF"
   },
   "source": [
    "## Running Gradient Descent\n",
    "\n",
    "Let's put together the code for a single gradient descent step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Zl_Nu_wB8ar4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:\n",
      " [2 1 0 2 0 2]\n",
      "predictions:\n",
      " [[0.025 0.201 0.774]\n",
      " [0.084 0.673 0.243]\n",
      " [0.99  0.006 0.003]\n",
      " [0.007 0.154 0.838]\n",
      " [0.962 0.032 0.006]\n",
      " [0.014 0.081 0.905]]\n",
      "loss: 0.43657251861677077\n",
      "gradient:\n",
      " [[ 0.012 -0.026  0.026  0.023]\n",
      " [-0.01   0.026 -0.007  0.01 ]\n",
      " [-0.001 -0.    -0.018 -0.033]]\n",
      "weights:\n",
      " [[0.539 1.556 0.295 0.347]\n",
      " [1.08  0.492 1.132 0.922]\n",
      " [1.381 0.951 1.573 1.731]]\n"
     ]
    }
   ],
   "source": [
    "# Run gradient descent\n",
    "m, n = X.shape  # m = number of examples; n = number of features (including bias)\n",
    "learning_rate = 0.01\n",
    "\n",
    "for _ in range(1000):\n",
    "  preds = softmax(np.dot(X_train, W.T))\n",
    "  loss = ce_loss(preds, Y_train)\n",
    "  gradient = np.dot((preds - tf.keras.utils.to_categorical(Y_train)).T, X_train) / m\n",
    "  W = W - learning_rate * gradient\n",
    "\n",
    "print('labels:\\n', Y_train[:6])\n",
    "print('predictions:\\n', preds[:6])\n",
    "print('loss:', loss)\n",
    "print('gradient:\\n', gradient)\n",
    "print('weights:\\n', W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8q72Tu_n_LlO"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "tj3z7t6-_PZ4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "test_preds = softmax(np.dot(X_test, W.T))\n",
    "test_pred_labels = np.argmax(test_preds, axis=1)\n",
    "print('Accuracy:', np.mean(test_pred_labels == Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xcq8zqKDALmC"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cf = tf.math.confusion_matrix(Y_test, test_pred_labels)\n",
    "ax = sns.heatmap(cf, annot=True, fmt='.3g', cmap='Blues',\n",
    "                 xticklabels=class_names, yticklabels=class_names, cbar=False)\n",
    "ax.set(xlabel='Predicted Label', ylabel='True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMsSJ-ZD_12e"
   },
   "source": [
    "## Now with TensorFlow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jisaFtGY__KL"
   },
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=3,                     # output dim\n",
    "    input_shape=[4],             # input dim\n",
    "    use_bias=False,              # we included the bias in X\n",
    "    activation='softmax',        # apply a sigmoid to the output\n",
    "    kernel_initializer=tf.ones_initializer,  # initialize params to 1\n",
    "))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3PQ-RDwXCKVt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step\n",
      "predictions:\n",
      " [[0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]\n",
      " [0.333 0.333 0.333]]\n",
      "loss: 0.9869160652160645\n",
      "W:\n",
      " [[ 0.263  2.958 -0.796 -0.728]\n",
      " [ 1.635 -0.238  2.101  0.152]\n",
      " [ 1.215  0.66   2.03   2.965]]\n"
     ]
    }
   ],
   "source": [
    "# As above, get predictions for the current model first.\n",
    "preds = model.predict(X)\n",
    "\n",
    "# Do a single gradient update.\n",
    "history = model.fit(\n",
    "  x = X_train,\n",
    "  y = Y_train,\n",
    "  epochs=100,\n",
    "  batch_size=10,\n",
    "  verbose=0)\n",
    "\n",
    "# Show the loss (before the update) and the new weights.\n",
    "loss = history.history['loss'][0]\n",
    "weights = model.layers[0].get_weights()[0].T\n",
    "print('predictions:\\n', preds[:6])\n",
    "print('loss:', loss)\n",
    "print('W:\\n', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "QAmb6PMCTVET"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9869160652160645, 0.7945044040679932, 0.6722151041030884, 0.595694899559021, 0.5485548973083496, 0.5147176384925842, 0.4920400381088257, 0.4744356870651245, 0.46144241094589233, 0.4516833424568176, 0.44234588742256165, 0.43434038758277893, 0.4279704988002777, 0.4221849739551544, 0.4174249768257141, 0.41185909509658813, 0.40734848380088806, 0.4041825532913208, 0.3997149169445038, 0.3968726098537445, 0.3946399986743927, 0.3905244469642639, 0.38892504572868347, 0.3855087161064148, 0.3830218017101288, 0.38102099299430847, 0.3789944052696228, 0.37708327174186707, 0.3755602240562439, 0.3734418451786041, 0.37209826707839966, 0.3701830208301544, 0.3687339723110199, 0.367420494556427, 0.36601200699806213, 0.3649790287017822, 0.36384743452072144, 0.3627813458442688, 0.3612792491912842, 0.36103057861328125, 0.3595670461654663, 0.35975581407546997, 0.35786980390548706, 0.35714948177337646, 0.35634124279022217, 0.3555372655391693, 0.3544948101043701, 0.35471439361572266, 0.3529798090457916, 0.35233527421951294, 0.35204723477363586, 0.35150906443595886, 0.3509501516819, 0.35023748874664307, 0.34956347942352295, 0.3499842584133148, 0.34855642914772034, 0.34887462854385376, 0.34756484627723694, 0.3481766879558563, 0.3466913104057312, 0.34635865688323975, 0.3457895517349243, 0.34534382820129395, 0.3455599844455719, 0.3450973629951477, 0.3444104492664337, 0.34416458010673523, 0.3439066410064697, 0.3442543148994446, 0.343151330947876, 0.3424617052078247, 0.342874675989151, 0.34222903847694397, 0.34205445647239685, 0.341349720954895, 0.3412170708179474, 0.34197998046875, 0.34070885181427, 0.3403674066066742, 0.34006646275520325, 0.339722216129303, 0.3397427797317505, 0.3399636447429657, 0.33910179138183594, 0.3386341333389282, 0.3392258584499359, 0.33810245990753174, 0.3380054831504822, 0.33842140436172485, 0.3383408486843109, 0.3377982974052429, 0.3373081088066101, 0.336995005607605, 0.33690616488456726, 0.3364638090133667, 0.33676666021347046, 0.3362155258655548, 0.3360554575920105, 0.3357745110988617]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DuKK7l4fTktl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step\n",
      "0.9\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25559672713279724"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = model.predict(X_test)\n",
    "test_preds_labels = np.argmax(test_preds, axis=1)\n",
    "accuracy = np.mean(test_preds_labels == Y_test)\n",
    "print(accuracy)\n",
    "model.evaluate(x=X_test, y=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOF/SzfGqGLnE58b8QnQuUU",
   "name": "03 Multiclass Logistic Regression.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
